{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Blockchain Data Discovery: Visualization\n",
                "\n",
                "This notebook visualizes the insights from the Arbitrum blockchain data (Uniswap V3 Swaps & Aave V3 Liquidations)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sqlite3\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# Set style\n",
                "sns.set_theme(style=\"whitegrid\")\n",
                "plt.rcParams['figure.figsize'] = [12, 6]\n",
                "\n",
                "DB_PATH = \"blockchain.db\"\n",
                "\n",
                "# Constants\n",
                "DECIMALS = {'WETH': 18, 'USDC': 6, 'AAVE': 18, 'DAI': 18, 'WBTC': 8}\n",
                "PRICES = {'WETH': 3100.0, 'USDC': 1.0, 'AAVE': 90.0, 'DAI': 1.0, 'WBTC': 95000.0}\n",
                "\n",
                "def get_connection():\n",
                "    return sqlite3.connect(DB_PATH)\n",
                "\n",
                "def normalize_amount(amount, token_symbol):\n",
                "    decimals = DECIMALS.get(token_symbol, 18)\n",
                "    return float(amount) / (10 ** decimals)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. MEV Sandwich Attack Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "conn = get_connection()\n",
                "query = \"\"\"\n",
                "SELECT transaction_hash, block_number, block_timestamp, log_index, sender, recipient, amount0, amount1, sqrt_price_x96, liquidity\n",
                "FROM uniswap_swaps_v2\n",
                "ORDER BY block_number, log_index\n",
                "\"\"\"\n",
                "df_swaps = pd.read_sql_query(query, conn)\n",
                "df_swaps['amount0'] = df_swaps['amount0'].apply(float)\n",
                "df_swaps['amount1'] = df_swaps['amount1'].apply(float)\n",
                "df_swaps['sqrt_price_x96'] = df_swaps['sqrt_price_x96'].apply(float)\n",
                "df_swaps['timestamp'] = pd.to_datetime(df_swaps['block_timestamp'], unit='s')\n",
                "\n",
                "# Pool Classification & Volume Calculation\n",
                "def classify_pool(row):\n",
                "    p = row['sqrt_price_x96']\n",
                "    if p < 1e27: return 'WETH/USDT'\n",
                "    elif p < 1e31: return 'WBTC/WETH'\n",
                "    else: return 'USDC/WETH'\n",
                "\n",
                "df_swaps['pool'] = df_swaps.apply(classify_pool, axis=1)\n",
                "\n",
                "def calc_volume(row):\n",
                "    pool = row['pool']\n",
                "    a0 = abs(row['amount0'])\n",
                "    a1 = abs(row['amount1'])\n",
                "    if pool == 'WETH/USDT': # T0=WETH(18), T1=USDT(6)\n",
                "        return max((a0/1e18)*PRICES['WETH'], (a1/1e6)*1.0)\n",
                "    elif pool == 'WBTC/WETH': # T0=WBTC(8), T1=WETH(18)\n",
                "        return max((a0/1e8)*PRICES['WBTC'], (a1/1e18)*PRICES['WETH'])\n",
                "    elif pool == 'USDC/WETH': # T0=USDC(6), T1=WETH(18)\n",
                "        return max((a0/1e6)*PRICES['USDC'], (a1/1e18)*PRICES['WETH'])\n",
                "    return 0.0\n",
                "\n",
                "df_swaps['volume_usd'] = df_swaps.apply(calc_volume, axis=1)\n",
                "\n",
                "# Detect Sandwiches (Updated with Profit Check)\n",
                "grouped = df_swaps.groupby('block_number')\n",
                "sandwiches = []\n",
                "\n",
                "for block_num, group in grouped:\n",
                "    if len(group) < 3: continue\n",
                "    group = group.sort_values('log_index')\n",
                "    txs = group.to_dict('records')\n",
                "    \n",
                "    for i in range(len(txs) - 2):\n",
                "        tx1 = txs[i]\n",
                "        dir1 = 1 if tx1['amount0'] < 0 else -1\n",
                "        for j in range(i + 1, len(txs) - 1):\n",
                "            tx2 = txs[j]\n",
                "            dir2 = 1 if tx2['amount0'] < 0 else -1\n",
                "            if dir1 != dir2: continue\n",
                "            for k in range(j + 1, len(txs)):\n",
                "                tx3 = txs[k]\n",
                "                dir3 = 1 if tx3['amount0'] < 0 else -1\n",
                "                if dir1 == dir3: continue\n",
                "                \n",
                "                if tx1['recipient'] == tx3['recipient']:\n",
                "                    # Calculate Profit\n",
                "                    profit0_raw = tx1['amount0'] + tx3['amount0']\n",
                "                    profit1_raw = tx1['amount1'] + tx3['amount1']\n",
                "                    # Normalize (Corrected Mapping: Token0=WETH, Token1=USDC)\n",
                "                    profit0 = normalize_amount(profit0_raw, 'WETH')\n",
                "                    profit1 = normalize_amount(profit1_raw, 'USDC')\n",
                "                    profit_usd = (profit0 * PRICES['WETH']) + (profit1 * PRICES['USDC'])\n",
                "                    \n",
                "                    if True: # Show all potential sandwiches\n",
                "                        sandwiches.append({\n",
                "                            'block_number': block_num,\n",
                "                            'attacker': tx1['recipient'],\n",
                "                            'profit_usd': profit_usd,\n",
                "                            'victim_tx_hash': tx2['transaction_hash']\n",
                "                        })\n",
                "\n",
                "df_mev = pd.DataFrame(sandwiches)\n",
                "print(f\"Found {len(df_mev)} profitable sandwiches\")\n",
                "if not df_mev.empty:\n",
                "    display(df_mev.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not df_mev.empty:\n",
                "    plt.figure(figsize=(10, 6))\n",
                "    sns.histplot(data=df_mev, x='profit_usd', bins=10, kde=True, color='orange')\n",
                "    plt.title('Distribution of MEV Sandwich Profits (USD)')\n",
                "    plt.xlabel('Profit (USD)')\n",
                "    plt.ylabel('Frequency')\n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Volume & Activity Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Volume Distribution (Log Scale)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.histplot(data=df_swaps, x='volume_usd', bins=50, log_scale=True, color='teal')\n",
                "plt.title('Distribution of Swap Sizes (USD) - Log Scale')\n",
                "plt.xlabel('Swap Volume (USD)')\n",
                "plt.ylabel('Count')\n",
                "plt.show()\n",
                "\n",
                "# 2. Hourly Activity\n",
                "df_hourly = df_swaps.set_index('timestamp').resample('H').agg({'volume_usd': 'sum', 'transaction_hash': 'count'})\n",
                "\n",
                "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "color = 'tab:blue'\n",
                "ax1.set_xlabel('Time')\n",
                "ax1.set_ylabel('Total Volume (USD)', color=color)\n",
                "ax1.plot(df_hourly.index, df_hourly['volume_usd'], color=color, marker='o')\n",
                "ax1.tick_params(axis='y', labelcolor=color)\n",
                "\n",
                "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
                "\n",
                "color = 'tab:red'\n",
                "ax2.set_ylabel('Transaction Count', color=color)\n",
                "ax2.plot(df_hourly.index, df_hourly['transaction_hash'], color=color, linestyle='--', alpha=0.7)\n",
                "ax2.tick_params(axis='y', labelcolor=color)\n",
                "\n",
                "plt.title('Hourly Trading Volume & Activity')\n",
                "fig.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Liquidation Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "query_liq = \"\"\"\n",
                "SELECT transaction_hash, collateral_asset, debt_asset, user, debt_covered, collateral_amount, liquidator\n",
                "FROM aave_liquidations_v2\n",
                "\"\"\"\n",
                "df_liq = pd.read_sql_query(query_liq, conn)\n",
                "conn.close()\n",
                "\n",
                "df_liq['debt_covered'] = df_liq['debt_covered'].apply(float)\n",
                "df_liq['debt_norm'] = df_liq['debt_covered'] / 1e18 # Normalize\n",
                "df_liq['est_profit_usd'] = df_liq['debt_norm'] * 0.05 * 3000 # Est 5% bonus\n",
                "\n",
                "# Top Liquidators\n",
                "top_liquidators = df_liq.groupby('liquidator')['est_profit_usd'].sum().sort_values(ascending=False).head(5)\n",
                "top_liquidators = top_liquidators.reset_index()\n",
                "top_liquidators['short_addr'] = top_liquidators['liquidator'].apply(lambda x: x[:6] + '...' + x[-4:])\n",
                "\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.barplot(data=top_liquidators, x='short_addr', y='est_profit_usd', palette='viridis')\n",
                "plt.title('Top 5 Liquidators by Estimated Profit')\n",
                "plt.xlabel('Liquidator Address')\n",
                "plt.ylabel('Estimated Profit (USD)')\n",
                "plt.xticks(rotation=45)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}